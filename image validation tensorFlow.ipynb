{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title Import library (step 01)\n",
        "from google.colab import files\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import zipfile\n",
        "import os\n",
        "import time"
      ],
      "metadata": {
        "id": "OhzDmoVwjN_e",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load dataset (step 02)\n",
        "!wget link_dataset \\\n",
        "  https://github.com/dicodingacademy/assets/releases/download/release/rockpaperscissors.zip"
      ],
      "metadata": {
        "cellView": "form",
        "id": "JVF2r5pMkeQy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Extract dataset (step 03)\n",
        "import os\n",
        "import zipfile\n",
        "# Ekstrak data file zip\n",
        "local_zip = '/content/rockpaperscissors.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/content/rockpaperscissors')\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "id": "65dwcT-1lJe-",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Direktori dataset (step 04)\n",
        "os.listdir('/content/rockpaperscissors/rockpaperscissors')\n",
        "['rps-cv-images', 'scissors', 'rock', 'README_rpc-cv-images.txt', 'paper']"
      ],
      "metadata": {
        "id": "7A-jukDro5Hv",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Path Target Directory (step 05)\n",
        "base_dir = '/content/rockpaperscissors/rockpaperscissors/rps-cv-images'"
      ],
      "metadata": {
        "id": "SrPvblRWaxJ1",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title gambar training proses (step 06)\n",
        "paper = os.path.join('/content/rockpaperscissors/rockpaperscissors/paper')\n",
        "rock = os.path.join('/content/rockpaperscissors/rockpaperscissors/rock')\n",
        "scissors = os.path.join('/content/rockpaperscissors/rockpaperscissors/scissors')"
      ],
      "metadata": {
        "id": "WMDcDP5qb3fa",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title list directory (step 07)\n",
        "train_paper = os.listdir(paper)\n",
        "train_rock = os.listdir(rock)\n",
        "train_scissors = os.listdir(scissors)\n",
        "\n",
        "print('Total training paper images:', len(train_paper))\n",
        "print('Total training paper rock:', len(train_rock))\n",
        "print('Total training scissors:', len(train_scissors))"
      ],
      "metadata": {
        "id": "DKSRiFdfhLrL",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title datagenerator keras ke data augmentation (step 08)\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "ZgqcxHrziZYY",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title skala dan posisi gambar (step 09)\n",
        "train_datagen = ImageDataGenerator(rescale=1./255, rotation_range=20,\n",
        "                                   horizontal_flip=True, shear_range=0.2,\n",
        "                                   fill_mode='wrap', validation_split=0.4)\n",
        "train_datagen"
      ],
      "metadata": {
        "id": "2RaWeW4YpXtJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b5dc8e2-207d-46b2-eaf8-38331bdcc71d",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.preprocessing.image.ImageDataGenerator at 0x7c5f91e5d600>"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title flow generate augemented dan ukuran pixel (step 10)\n",
        "train_gen = train_datagen.flow_from_directory(base_dir, target_size=(100,150),\n",
        "                                              shuffle=True,\n",
        "                                              class_mode='categorical', subset='training')\n",
        "validation_gen = train_datagen.flow_from_directory(base_dir, target_size=(100,150),\n",
        "                                                   shuffle=True,\n",
        "                                                   class_mode='categorical', subset='validation')"
      ],
      "metadata": {
        "id": "njqnm-TxrGfR",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Tampilak sampel (step 11)\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "nrows = 5\n",
        "ncols = 5\n",
        "\n",
        "pic_index = 0\n",
        "\n",
        "fig = plt.gcf ()\n",
        "fig.set_size_inches(ncols * 5, nrows * 5)\n",
        "\n",
        "pic_index += 8\n",
        "next_paper_pix = [os.path.join(paper, fname)\n",
        "                for fname in train_paper[pic_index-8:pic_index]]\n",
        "next_rock_pix = [os.path.join(rock, fname)\n",
        "                for fname in train_rock[pic_index-8:pic_index]]\n",
        "next_scissors_pix = [os.path.join(scissors, fname)\n",
        "                for fname in train_scissors[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_paper_pix+next_rock_pix+next_scissors_pix):\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('off')\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)"
      ],
      "metadata": {
        "id": "yiDx58WZycrG",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title model CNN (step 12)\n",
        "model = tf.keras.models.Sequential([\n",
        "          tf.keras.layers.Conv2D(32, (3,3), activation = 'relu', input_shape=(100,150,3)),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Conv2D(128, (3,3), activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Conv2D(256, (3,3), activation='relu'),\n",
        "          tf.keras.layers.MaxPooling2D(2,2),\n",
        "          tf.keras.layers.Dense (512, activation='relu'),\n",
        "          tf.keras.layers.Dense(3, activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "5IvAD4gZ39Qe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title ringkasan model (step 13)\n",
        "model.summary()"
      ],
      "metadata": {
        "id": "mBnn4G5z7N_0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title compile model (step 14)\n",
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer=tf.optimizers.Adam(),\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "OL72eNTr8Mrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title limit stop 98% (step 15)\n",
        "accuracy_threshold = 98e-2\n",
        "class my_callbacks(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs=None):\n",
        "    if logs.get('accuracy') >= accuracy_threshold:\n",
        "      print('\\nFor Epoch', epoch,\n",
        "            '\\nAccuracy has reach %2.2f%%' %(logs['accuracy']*100),\n",
        "            ', training has been stopped')\n",
        "      self.model.stop_training = True"
      ],
      "metadata": {
        "id": "JI8CswGH-ovG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "history = model.fit(train_gen, steps_per_epoch=25, epochs=20,\n",
        "                    validation_data=validation_gen,\n",
        "                    validation_steps=5, verbose=2,\n",
        "                    callbacks=[my_callbacks()])"
      ],
      "metadata": {
        "id": "sGRjkvKY93sX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "plt.plot(history.history['loss'],label='Train')\n",
        "plt.plot(history.history['val_loss'],label='Validation')\n",
        "plt.legend()"
      ],
      "metadata": {
        "id": "XHTncpzkhnvH",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Default title text\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "uploaded = files.upload()\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "   path = fn\n",
        "   img = image.load_img(path, target_size=(100, 150))\n",
        "   x = image.img_to_array(img)\n",
        "   x = np.expand_dims(x, axis=0)\n",
        "\n",
        "   images = np.vstack([x])\n",
        "   classes = model.predict(images, batch_size=10)\n",
        "   plt.axis('off')\n",
        "   plt.imshow(img)\n",
        "   plt.show()\n",
        "\n",
        "   print(fn)\n",
        "   if classes[0,0]==1:\n",
        "     print('Image Classifier: Rock')\n",
        "   elif classes[0,1]==1:\n",
        "     print('Image Classifier: Paper')\n",
        "   elif classes[0,2]==1:\n",
        "     print('Image Classifier: Scissor')\n",
        "   else:\n",
        "      print('Image Classifier: None')"
      ],
      "metadata": {
        "id": "RxuslOMjjNGn"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}